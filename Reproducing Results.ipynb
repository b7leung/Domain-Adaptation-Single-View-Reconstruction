{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook can be used to reproduce the results in all figures in our paper \"Domain Adaptation for Real-World Single View 3D Reconstruction\" (Brandon Leung, Siddharth Singh, Arik Horodniceanu) for CSE 291: Domain Adaptation in Computer Vision.\n",
    "\n",
    "First, please download our source code here:\n",
    "\n",
    "\n",
    "Python 3.7 is recommended. Note that the following depencencies are required:\n",
    "* argparse\n",
    "* easydict\n",
    "* matplotlib\n",
    "* numpy\n",
    "* opencv-python\n",
    "* pprint\n",
    "* scipy\n",
    "* pytorch\n",
    "* torchvision\n",
    "* pandas\n",
    "* tqdm\n",
    "* sklearn\n",
    "\n",
    "You will also need to download the following datasets:\n",
    "* Shapenet rendering images http://cvgl.stanford.edu/data2/ShapeNetRendering.tgz\n",
    "* shapenet voxelized models http://cvgl.stanford.edu/data2/ShapeNetVox32.tgz\n",
    "* ODDS dataset https://drive.google.com/open?id=1ZrljEGjqjduODVEXYL4dvIVO-DQzakc2\n",
    "\n",
    "Once downloaded, please update config.py with the location of the downloaded datasets on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T23:26:56.940141Z",
     "start_time": "2020-03-21T23:26:56.778948Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T23:26:59.043895Z",
     "start_time": "2020-03-21T23:26:59.026909Z"
    }
   },
   "outputs": [],
   "source": [
    "# A GPU is required. If there are multiple GPUs, please set the desired one here.\n",
    "from config import cfg\n",
    "import os\n",
    "cfg.CONST.DEVICE = \"3\"\n",
    "# need to set gpus before anything involving pytorch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cfg.CONST.DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T23:27:04.182327Z",
     "start_time": "2020-03-21T23:27:01.366364Z"
    }
   },
   "outputs": [],
   "source": [
    "from core.train import train_net\n",
    "from core.test import test_net\n",
    "import torch\n",
    "import pprint\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T23:27:06.836974Z",
     "start_time": "2020-03-21T23:27:06.804924Z"
    }
   },
   "outputs": [],
   "source": [
    "def embed_TSNE(data):\n",
    "    X_embedded = data\n",
    "    X_embedded = PCA(n_components = 50, svd_solver='auto').fit_transform(X_embedded)\n",
    "    X_embedded = TSNE(n_components=2).fit_transform(X_embedded) \n",
    "    return X_embedded\n",
    "\n",
    "def visualize_tsne(embedded_latent_vectors, class_labels, title=\"TSNE\"):\n",
    "    \n",
    "    embedded_df = pd.DataFrame(embedded_latent_vectors) \n",
    "    ax = embedded_df.plot.scatter(x=0, y = 1, c = class_labels, colormap=\"viridis\")\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_names = []\n",
    "weights_paths = [\n",
    "    \"./output_submission/author_saved_params/Pix2Vox-A-ShapeNet.pth\",\n",
    "    \"./output_submission/2020_03_19--18_54_21_OOWL_DA_CORAL_lam_10_TRAIN/checkpoints/best-ckpt.pth\",\n",
    "    \"./output_submission/2020_03_19--21_49_02_OOWL_DA_DANN_lam_1_TRAIN/checkpoints/best-ckpt.pth\",\n",
    "]\n",
    "\n",
    "for weights_path in weights_paths:\n",
    "    cfg.CONST.WEIGHTS = weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T23:27:35.655266Z",
     "start_time": "2020-03-21T23:27:27.611209Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 2020-03-21 16:27:27.645588 Collecting files of Taxonomy[ID=Airplane_Model, Name=Airplane_Model]\n",
      "[INFO] 2020-03-21 16:27:27.647326 Collecting files of Taxonomy[ID=Boat_Model, Name=Boat_Model]\n",
      "[INFO] 2020-03-21 16:27:27.648714 Collecting files of Taxonomy[ID=Car_Model, Name=Car_Model]\n",
      "[INFO] 2020-03-21 16:27:27.649912 Collecting files of Taxonomy[ID=Lamp, Name=Lamp]\n",
      "[INFO] 2020-03-21 16:27:27.651050 Collecting files of Taxonomy[ID=Monitor, Name=Monitor]\n",
      "[INFO] 2020-03-21 16:27:27.652386 Collecting files of Taxonomy[ID=Telephone, Name=Telephone]\n",
      "[INFO] 2020-03-21 16:27:27.653757 Complete collecting files of the dataset. Total files: 93.\n",
      "[INFO] 2020-03-21 16:27:35.411815 Loading weights from ./output_submission/2020_03_21--01_49_04_OWILDVoxelCls_VoxLamExp_DANNlam1_TRAIN/checkpoints/best-ckpt.pth ...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './output_submission/2020_03_21--01_49_04_OWILDVoxelCls_VoxLamExp_DANNlam1_TRAIN/checkpoints/best-ckpt.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f4dd6a776f94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSE_TRAIN_SET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_VIEWS_RENDERING\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_class_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_latent_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mt_embedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_TSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_latent_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data7/brandon/research/DA_MVR/Pix2Vox/core/test.py\u001b[0m in \u001b[0;36mtest_net\u001b[0;34m(cfg, epoch_idx, output_dir, test_data_loader, encoder, decoder, refiner, merger)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[INFO] %s Loading weights from %s ...'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWEIGHTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWEIGHTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mepoch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch_idx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoder_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data7/drone_machinelearning/anaconda3/envs/standard/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data7/drone_machinelearning/anaconda3/envs/standard/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data7/drone_machinelearning/anaconda3/envs/standard/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './output_submission/2020_03_21--01_49_04_OWILDVoxelCls_VoxLamExp_DANNlam1_TRAIN/checkpoints/best-ckpt.pth'"
     ]
    }
   ],
   "source": [
    "cfg.CONST.WEIGHTS = \"./output_submission/2020_03_21--01_49_04_OWILDVoxelCls_VoxLamExp_DANNlam1_TRAIN/checkpoints/best-ckpt.pth\"\n",
    "\n",
    "# obtaining latent vectors for target domain\n",
    "cfg.DATASET.CLASSES_TO_USE = [\"aeroplane\", \"car\", \"display\", \"lamp\", \"telephone\", \"watercraft\"]\n",
    "cfg.DATASET.TEST_DATASET = \"OWILD\"\n",
    "cfg.TEST.USE_TRAIN_SET = True\n",
    "cfg.CONST.N_VIEWS_RENDERING = 8\n",
    "_, t_class_labels, t_latent_vectors = test_net(cfg)\n",
    "t_embedded = embed_TSNE(t_latent_vectors)\n",
    "\n",
    "# obtaining latent vectors for ShapeNet source domain\n",
    "cfg.DATASET.CLASSES_TO_USE = [\"aeroplane\"]\n",
    "#cfg.DATASET.CLASSES_TO_USE = [\"aeroplane\", \"car\", \"display\", \"lamp\", \"telephone\", \"watercraft\"]\n",
    "cfg.DATASET.TEST_DATASET = \"ShapeNet\"\n",
    "cfg.CONST.N_VIEWS_RENDERING=1\n",
    "\n",
    "_, s_class_labels, s_latent_vectors = test_net(cfg)\n",
    "s_embedded = embed_TSNE(s_latent_vectors)\n",
    "\n",
    "# show TSNE for source and target domains\n",
    "s_t_embedded = np.concatenate((s_embedded, t_embedded), axis =0)\n",
    "domain_labels = [0 for i in range(s_embedded.shape[0])] + [1 for i in range(t_embedded.shape[0])]\n",
    "visualize_tsne(s_t_embedded, domain_labels, \"Source and Target Domain t-SNE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
